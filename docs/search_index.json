[["index.html", "Probabilidade e Estatística Informações Gerais ", " Probabilidade e Estatística Paulo de Souza 2022-02-23 Informações Gerais "],["sobre-o-livro.html", "Sobre o Livro", " Sobre o Livro Este livro, é apenas um resumo baseado em anotações do autor, com o que diz respeito ao estudo de temas referentes a probabilidade e estatística. "],["uso.html", "Uso", " Uso O livro pode ser usado pelos entusiastas nos assuntos supracitados. "],["introdução.html", "Capítulo 1 Introdução ", " Capítulo 1 Introdução "],["conceitos-principais.html", "1.1 Conceitos Principais", " 1.1 Conceitos Principais Grupos independentes Grupos pareados Tipo paramétrico Tipo não paramétrico "],["testes-de-hipótese.html", "1.2 Testes de Hipótese", " 1.2 Testes de Hipótese 1.2.1 Hipósete nula e alternativa 1.2.2 O significado de p-valor "],["testes-de-comparação-amostral.html", "1.3 Testes de Comparação Amostral", " 1.3 Testes de Comparação Amostral São diversos os modelos de dados que são analisados, e cada um destes tem suas características probabilisticas; quando queremos comparar grupos amostrais de nossos dados, são necessários testes para entender melhor como essa amostra se comporta. Na Tabela abaixo são apresentados alguns dos principais testes de Comparação entre Amostras, cada um dos termos da tabela, assim como os métodos, serão explicados ao longo deste livro/resumo. Tabela 1.1: Testes Para Comparação de Amostras Quantidade Tipo Método de Teste 2 grupos independentes paramétricos Int. e lim. de confiança (1 ou 2 grupos) t de Student (1 ou 2 grupos) Comparação entre 2 proporções não paramétricos Qui-quadrado \\(\\chi^2\\) U de Mann Whitney Prova de Fischer 2 grupos pareados paramétrico t de Student pareado não paramétricos Prova de MacNemar Prova de Wilcoxon \\(\\geq\\) 3 grupos independentes paramétrico ANOVA de 1 ou 2 vias não paramétricos Qui-quadrado \\(\\chi^2\\) Kruskall Wallis \\(\\geq\\) 3 grupos pareados paramétrico ANOVA p/ medidas repetidas não paramétrico Teste de Friedman Na linha 1 da tabela 1.1 as abreviações Int e lim significam intervalo e limite, respectivamente. "],["estatística.html", "Capítulo 2 Estatística", " Capítulo 2 Estatística Em probabilidade e estatística, existem diversos conceitos e axiomas que são fundamentais para o entendimento e a resolução dos problemas. Neste capítulo serão desenvolvidos os pontos que serão mais aplicados ao decorrer do livro, demais conceitos que sejam considerados extras, serão apenas indicados e referências para estes são deixadas a disposição. "],["conceitos-básicos-de-estatística.html", "2.1 Conceitos Básicos de Estatística", " 2.1 Conceitos Básicos de Estatística Entre os conceitos mais básicos da estatística, estão a média, moda e mediana, de forma direta a explicação de cada uma é dada na sequência Média - Valor médio Mediana - O valor central Moda - O valor que mais se repete 2.1.1 Média A média como citado anteriormente, é o valor médio de uma sequência de dados, matematicamente isso significa a soma de todos os termos, divido pela quantidade dos termos, como apresentado na equação (2.1) \\[\\begin{equation} \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i \\tag{2.1} \\end{equation}\\] Para fixar melhor este conceito, vejamos o exemplo abaixo. Exemplo 2.1 Dado o seguinte registro da velocidade de 13 carros: vel = [99,86,87,88,111,86,103,87,94,78,77,85,86] calcular a média desses dados. Resolução: Para calcular a média, basta sormamos todos os termos e dividirmos pela quantidade de termos, isto é \\[ \\bar{x} = \\frac{1}{13}(99+86+87+111+86+103+87+94+78+77+85+86) = 89.77 \\] Portanto, a média das velocidades coletadas é \\(\\bar{x} = 89.77\\) Outro conceito que usualmente aparece, é o de média ponderada, neste caso é associado um determinado peso a cada um dos termos da amostra. 2.1.2 Mediana 2.1.3 Moda 2.1.4 Variância A Variância é um parâmetro que compara o quão distantes estão os valores de determinado grupo de dados com relação a média deste mesmo grupo. A mesma pode ser do tipo Amostral ou Populacional e a diferença fica mais explicita na equação que as definem. \\[\\begin{equation} s^2 = \\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})^2 \\end{equation}\\] 2.1.5 Desvio Padrão "],["probabilidade.html", "Capítulo 3 Probabilidade", " Capítulo 3 Probabilidade Neste capítulo serão apresentados os seguintes tópicos: Axiomas da Probabilidade Análises Combinatórias Distribuições de Probabilidade "],["análise-combinatória.html", "3.1 Análise Combinatória", " 3.1 Análise Combinatória "],["distribuições-de-probabilidade.html", "3.2 Distribuições de Probabilidade", " 3.2 Distribuições de Probabilidade São diversos os tipos de distribuições para análise de dados, podendo ser separado em dois grupos, o de distribuições discretas e o de distribuições contínuas; as mesmas ainda apresentam características importantes, são algumas delas: Função de Densidade de Probabilidade (PDF) Função de Densidade Acumulada (CDF) Função Percentil (PPF) Esperança e Variância da Distribuição (E(x) e V(x)) Na sequência são apresentadas variás dessas distribuições e suas características, além disso, é disposto implementações em Octave para se obter resultados de estudo. Na próxima seção, é feita uma bateria de exemplos que mostram como aquelas são utilizadas. 3.2.1 Normal Densidade de Probabilidade A fórmula geral para a Função Densidade de Probabilidade de uma Distribuição Normal é \\[\\begin{equation} f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\frac{-(x-\\mu)^2}{(2\\sigma^2)}} \\end{equation}\\] Nos casos em que \\(\\mu = 0\\) e \\(\\sigma = 1\\), temos a chamada função normal padrão, costumeiramente representado por \\(N(1,0)\\). A equação anterior se reduz a: \\[\\begin{equation} f(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{\\frac{-x^2}{2}} \\end{equation}\\] O seguinte gráfico é referente a PDF da normal padrão. Figure 3.1: Função Densidade de Probabilidade da Normal Padrão Densidade Acumulada A fórmula para o cálculo da Função Densidade Acumulada para uma distribuição normal padrão é dado por: \\[\\begin{equation} F(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2 \\pi}} e^{\\frac{-x^2}{2}} \\end{equation}\\] O seguinte gráfico representa os valores de CDF para uma distribuição normal padrão: Figure 3.2: Função Densidade Acumulada da Normal Padrão Função Percentil Não existe uma forma fechada de se calcular a função percentil para a distribuição normal; no entanto sua interpretação é que dado um valor de probabilidade \\(p\\) obtêm-se o valor de \\(x\\), isto é, ela é a inversa da CDF. No gráfico a seguir é apresentada a PPF da distribuição normal padrão. Figure 3.3: Função Percentil de Probabilidade da Normal Padrão 3.2.2 Uniforme Densidade de Probabilidade A Distribuição Uniforme tem sua Densidade de Probabilidade dada por: \\[\\begin{equation} f(x) = \\frac{1}{B-A} \\hspace{2cm} A \\leq x \\leq B \\end{equation}\\] Em que \\(A\\) é o parâmetro locação (ou desvio) e \\(B-A\\) é o parâmetro de escala. O gráfico a seguir mostra o caso em que \\(A = 1\\) e \\(B = 3\\). Figure 3.4: Função Densidade de Probabilidade da Uniforme Na ocasião em que \\(A = 0\\) e \\(B = 1\\), temos a chamada distribuição uniforme padrão, e a equação anterior se reduz a: \\[\\begin{equation} f(x) = 1 \\hspace{2cm} 0 \\leq x \\leq 1 \\end{equation}\\] O gráfico a seguir mostra a PDF da uniforme padrão. Figure 3.5: Função Percentil de Probabilidade da Normal Padrão Densidade Acumulada A Densidade Acumulada para um distribuição normal padrão, é simplesmente: \\[\\begin{equation} F(x) = x \\hspace{2cm} 0 \\leq x \\leq 1 \\end{equation}\\] O gráfico a seguir apresenta a curva da CDF para a normal padrão. Função Percentil A fórmula da Função Percentil para uma distribuição uniforme padrão é bem definida, e é expressa por: \\[\\begin{equation} G(p) = p \\hspace{2cm} 0 \\leq p \\leq 1 \\end{equation}\\] O gráfico da PPF da uniforme padrão é apresentado a seguir: 3.2.3 T-de-Student 3.2.4 F de Fisher - Snedecor 3.2.5 Qui - Quadrado 3.2.6 Exponencial 3.2.7 Weidbull 3.2.8 Geométrica 3.2.9 Hipergeométrica 3.2.10 Gama 3.2.11 Beta 3.2.12 Bernoulli 3.2.13 Binomial A Distribuição Binomial é um tipo de distribuição discreta, e uma decorrência dos ensaios de Bernoulli, quando o número de eventos sucesso é maior do que 1. Densidade de Probabilidade O cálculo referente a função Densidade de Probabilidade é dado pela função: \\[\\begin{equation} f(x;p,n) = \\binom{n}{x} (p)^x (1-p)^{n-x} \\end{equation}\\] Em que \\(x\\) é o número de vezes que o meu sucesso deve ocorrer, na ocasião \\(x\\) é um número inteiro positivo, isto é, \\(x = 0, 1, 2, \\cdots\\); \\(p\\) é a probabilidade do sucesso ocorrer uma única vez; \\(n\\) quantidade de eventos avaliados. Sendo ainda o termo \\(\\binom{n}{x}\\) a Combinação \\(C(n,x)\\), calculada por: \\[ C(n,x) = \\binom{n}{x} = \\frac{n!}{x!(n-x)!} \\] Densidade Acumulada Função Percentil 3.2.14 Binomial - Negativa 3.2.15 Poisson Densidade de Probabilidade A Distribuição de Poisson, é um tipo de distribuição discreta que tem como função de probabilidade a seguinte equação \\[\\begin{equation} f(x,\\lambda) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\end{equation}\\] Em que \\(x\\) é o número de ocorrências no estudo em questão, sendo este ainda um número inteiro não negativo, isto é, \\(x = 0, 1, 2, \\cdots\\); \\(\\lambda\\) é o número esperado (médio) de ocorrências no intervalo de estudo. Densidade Acumulada Função Percentil 3.2.16 Pareto "],["dois-grupos-independentes-e-paramétricos.html", "Capítulo 4 Dois Grupos Independentes e Paramétricos ", " Capítulo 4 Dois Grupos Independentes e Paramétricos "],["intervalo-e-limite-de-confiança.html", "4.1 Intervalo e limite de confiança", " 4.1 Intervalo e limite de confiança "],["t-de-student-1.html", "4.2 t de Student", " 4.2 t de Student "],["comparação-entre-2-proporções.html", "4.3 Comparação entre 2 proporções", " 4.3 Comparação entre 2 proporções "],["dois-grupos-independentes-e-não-paramétricos.html", "Capítulo 5 Dois Grupos Independentes e Não-Paramétricos ", " Capítulo 5 Dois Grupos Independentes e Não-Paramétricos "],["qui-quadrado.html", "5.1 Qui-Quadrado", " 5.1 Qui-Quadrado "],["u-de-mann-whitney.html", "5.2 U de Mann Whitney", " 5.2 U de Mann Whitney O teste de U de Mann Whitney, também conhecido como Soma do Posto de Wilcoxon é utilizado na comparação de dois grupos amostrais que tenham preferencialmente o mesmo tamanho. O método funciona com os seguintes passos: Coloca-se em ordem crescente todos os dados; Calcula-se o posto referente a cada um dos valores; Atribui-se este posto a cada um dos valores na amostra original; Soma-se o posto de cada uma das duas amostras; Calcula-se o valor \\(U_1\\) e \\(U_2\\), e toma-se \\(U = \\min(U_1,U_2)\\). Define-se as sequintes equações (5.1) e (5.2) para o cálculo de \\(U_1\\) e \\(U_2\\): \\[\\begin{equation} U_1 = n_1 n_2 + \\frac{n_1(n_1+1)}{2} - R_1 \\tag{5.1} \\end{equation}\\] \\[\\begin{equation} U_2 = n_1 n_2 + \\frac{n_2(n_2+1)}{2} - R_2 \\tag{5.2} \\end{equation}\\] Caso a quantidade de valores coletados seja menor que 20, isto é, a soma de \\(n_1\\) e \\(n_2\\) sejam menores que 20, deve ser feito o comparativo do valor de \\(U_{calculado}\\) com o valor de \\(U_{tabelado}\\), consultar a tabela Valores Críticos U de Mann-Whitney1. Se a população for maior que 20, é necessário usar a tabela z-normal; nesta ocasião é efetuado mais um passo, que é o cálculo de z. O calculo de \\(z\\) é dado por: \\[\\begin{equation} z = \\frac{U - \\mu_R}{\\sigma_R} \\tag{5.3} \\end{equation}\\] em que \\[ \\mu_R = \\frac{n_1 \\cdot n_2}{2} \\hspace{2cm} \\sigma_R = \\sqrt{\\frac{n_1 \\cdot n_2(n_1 + n_2 + 1)}{12}} \\] Vamos resolver um exemplo, para que fique mais clara a aplicação do método. Exemplo 5.1 Na investigação da eficiência de um novo remédio para asma, um grupo de 10 pacientes aleatórios são submetidos ao teste, sendo metade utilizando o novo remédio e a outra parte um placebo. Após uma semana os mesmos são questionados sobre a quantidade de crises que tiveram durante o período, os dados são apresentados na sequência. Placebo Novo Remédio 7 3 5 6 6 4 4 2 12 1 Tome um nível de \\(5\\%\\) de significancia para o teste e as seguintes hipóteses nula e alternativa \\(H_0\\): A duas populações são iguais \\(H_1\\): A duas populações não são iguais. Resolução Vamos tomar como Pl a coluna do Placebo e NR a coluna do Novo Remédio, então \\(n_{Pl} = 5\\) e \\(n_{NR} = 5\\); seguindo o passo a passo do método, iremos primeiro colocar todos os dados em ordem crescente, então fazemos: Passo 1 Colocando todos os dados em ordem crescente # ordem 1 2 3 4 4 5 6 6 7 12 Passo 2 Deve ser calculado o posto de cada valor; o posto de uma amostra é dado de acordo com a posição na qual os dados de mesmo valor estão localizados na sequência crescente e a quantidade dos mesmos. Por exemplo, na ocasião o primeiro valor repetido é o número 4, o mesmo está localizado na posição 4 e 5 (sendo então duas repetições) da lista ordenada, então o posto do valor 4 será \\[ \\text{posto}_4 = \\frac{4+5}{2} = 4.5 \\] o mesmo procedimento é feito para o valor 6, que se encontra na posição 7 e 8, logo: \\[ \\text{posto}_6 = \\frac{7+8}{2} = 7.5 \\] os demais valores irão assumir os postos de suas posições, sendo assim: # ordem 1 2 3 4 4 5 6 6 7 12 # postos 1 2 3 4.5 4.5 6 7.5 7.5 9 10 Passo 3 Agora deve-se atribuir o valor dos postos encontrados, em cada uma das amostras originais Placebo Posto Pl Novo Remédio Posto NR 7 9 3 3 5 6 6 7.5 6 7.5 4 4.5 4 4.5 2 2 12 10 1 1 Passo 4 Agora somaremos o posto de cada uma das amostras \\[ R_{Pl} = 9 + 6 + 7.5 + 4.5 + 10 = 37\\\\ R_{NR} = 3 + 7.5 + 4.5 + 2 + 1 = 18 \\] Passo 5 Iremos calcular o valor de U, o que segue: Primeiro \\(U_{Pl}\\) \\[ U_{Pl} = n_{Pl} \\cdot n_{NR} + \\frac{n_{Pl}(n_{Pl}+1)}{2} - R_{Pl} \\hspace{1cm} \\therefore \\] \\[ U_{Pl} = 5 \\cdot 5 + \\frac{5(5+1)}{2} - 37 \\hspace{.5cm} \\Rightarrow \\hspace{.5cm} U_{Pl} = 3 \\] e agora \\(U_{NR}\\) \\[ U_{NR} = n_{Pl} \\cdot n_{NR} + \\frac{n_{NR}(n_{NR}+1)}{2} - R_{NR} \\hspace{1cm} \\therefore \\] \\[ U_{NR} = 5 \\cdot 5 + \\frac{5(5+1)}{2} - 18 \\hspace{.5cm} \\Rightarrow \\hspace{.5cm} U_{NR} = 22 \\] Com ambos os valores calculados, tomaremos o menor, sendo assim \\(U = 3\\), como a amostra só tem 10 valores, podemos então olhar a tabela de valor critíco U de Mann Whitney, uma parte da mesma é apresentada na figura a seguir Figure 5.1: Parte da Tabela de Valores Críticos de U Como nosso \\(n_1 = 5, \\ n_2 = 5\\) e \\(\\alpha = 5\\%\\), temos \\(U_{tabelado} = 2\\); sendo o U calculado maior que o tabelado, \\(2 &lt; 3\\), então a hipótese nula é aceita. OBS: O exercício foi retirado e adaptado do site Mann-Whitney Para automatizar o problema foi criada uma função em Octave na qual é apresentada na sequência function testeU_MannWhitney(A,B) display(&#39;Dados fornecidos&#39;) display(A) display(B) nA = length(A); %quantidade de observacoes em A nB = length(B); %quantidade de observacoes em B n = nA+nB; %quantidade de observacoes totais C = [A,B]; %vetor auxiliar C_cres = sort(C); %vetor auxiliar em ordem crescente %Pesos em A for k=1:nA mA = find(C_cres == A(k)); pesoA(k) = sum(mA)/length(mA); end RA = sum(pesoA); %Pesos em B for k=1:nB mB = find(C_cres == B(k)); pesoB(k) = sum(mB)/length(mB); end RB = sum(pesoB); for k=1:nA if k == 1 fprintf(&#39;Valor A rankA\\n&#39;) end fprintf(&#39;%7.2f %10.2f\\n&#39;,A(k),pesoA(k)) if k==nA fprintf(&#39;nA = %4.2f RA = %5.2f\\n\\n&#39;,nA,RA) end end for k=1:nB if k == 1 fprintf(&#39;Valor B rankB\\n&#39;) end fprintf(&#39;%7.2f %10.2f\\n&#39;,B(k),pesoB(k)) if k==nB fprintf(&#39;nB = %4.2f RB = %5.2f\\n\\n&#39;,nB,RB) end end %Estatistica para o teste de Mann Whitney UA = nA*nB + 0.5*(nA*(nA+1))-RA; UB = nA*nB + 0.5*(nB*(nB+1))-RB; fprintf(&#39;UA = %.2f UB = %.2f\\n&#39;,UA,UB) U = min(UA,UB); %Para n&gt;20 usa-se a tabela da distribuicao normal if n&gt;20 display(&#39;Use a Tabela normal&#39;) mu_r = nA*nB/2; sig_r = sqrt((nA*nB)*(nA+nB+1)/12); z = (U-mu_r)/sig_r %Para n&lt;=20 usa-se a tabela de Valores Criticos de Mann-Whitney else display(&#39;Use a Tabela de Mann-Whitney&#39;) fprintf(&#39;Sendo o valor calculado de U = %.2f\\n&#39;,U) end Para o nosso exemplo então podemos definir Pl = [7 5 6 4 12], NR = [3 6 4 2 1] e usar o comando testeU_MannWhitney(Pl,NR), o resultado obtido é apresentado na sequência ## Dados fornecidos ## A = ## ## 7 5 6 4 12 ## ## B = ## ## 3 6 4 2 1 ## ## Valor A rankA ## 7.00 9.00 ## 5.00 6.00 ## 6.00 7.50 ## 4.00 4.50 ## 12.00 10.00 ## nA = 5.00 RA = 37.00 ## ## Valor B rankB ## 3.00 3.00 ## 6.00 7.50 ## 4.00 4.50 ## 2.00 2.00 ## 1.00 1.00 ## nB = 5.00 RB = 18.00 ## ## UA = 3.00 UB = 22.00 ## Use a Tabela de Mann-Whitney ## Sendo o valor calculado de U = 3.00 Tabela de Mann Whitney "],["prova-de-fischer.html", "5.3 Prova de Fischer", " 5.3 Prova de Fischer "],["dois-grupos-pareados-e-paramétricos.html", "Capítulo 6 Dois grupos Pareados e Paramétricos ", " Capítulo 6 Dois grupos Pareados e Paramétricos "],["teste-de-t-student-pareado.html", "6.1 Teste de t-Student pareado", " 6.1 Teste de t-Student pareado "],["dois-grupos-pareados-e-não---paramétricos.html", "Capítulo 7 Dois grupos Pareados e Não - Paramétricos ", " Capítulo 7 Dois grupos Pareados e Não - Paramétricos "],["prova-de-macnemar.html", "7.1 Prova de MacNemar", " 7.1 Prova de MacNemar "],["prova-de-wilcoxon.html", "7.2 Prova de Wilcoxon", " 7.2 Prova de Wilcoxon "],["três-ou-mais-grupos-independentes-e-paramétricos.html", "Capítulo 8 Três ou mais grupos Independentes e Paramétricos ", " Capítulo 8 Três ou mais grupos Independentes e Paramétricos "],["teste-de-tuckey.html", "8.1 Teste de Tuckey", " 8.1 Teste de Tuckey "],["anova-de-1-ou-2-vias.html", "8.2 ANOVA de 1 ou 2 vias", " 8.2 ANOVA de 1 ou 2 vias "],["testes-de-normalidade.html", "Capítulo 9 Testes de Normalidade ", " Capítulo 9 Testes de Normalidade "],["shapiro-wilk.html", "9.1 Shapiro-Wilk", " 9.1 Shapiro-Wilk "],["kolmogorov---smirnov.html", "9.2 Kolmogorov - Smirnov", " 9.2 Kolmogorov - Smirnov "],["anderson---darling.html", "9.3 Anderson - Darling", " 9.3 Anderson - Darling "],["cramer-von-mises.html", "9.4 Cramer Von-Mises", " 9.4 Cramer Von-Mises "],["análise-de-concordância-de-atributos.html", "Capítulo 10 Análise de Concordância de Atributos", " Capítulo 10 Análise de Concordância de Atributos "],["estática-kappa.html", "Capítulo 11 Estática Kappa ", " Capítulo 11 Estática Kappa "],["teste-kappa-de-cohen.html", "11.1 Teste Kappa de Cohen", " 11.1 Teste Kappa de Cohen "],["teste-kappa-de-fleiss.html", "11.2 Teste Kappa de Fleiss", " 11.2 Teste Kappa de Fleiss "],["referências.html", "Referências", " Referências "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
